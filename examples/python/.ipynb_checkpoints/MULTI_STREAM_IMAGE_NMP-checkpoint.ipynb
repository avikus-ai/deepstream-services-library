{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cut_ffmpeg.mp4\twangsan-lidar-sample-video.mp4\twangsan.mp4\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../../../datas/sample_video/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def extract_frame(video_path, frame_dir, overwrite=False, start=-1, end=-1, every=1):\n",
    "    \"\"\"\n",
    "    Extract frames from a video using OpenCVs VideoCapture\n",
    "    :param video_path: path of the video\n",
    "    :param frames_dir: the directory to save the frames\n",
    "    :param overwrite: to overwrite frames that already exist?\n",
    "    :param start: start frame\n",
    "    :param end: end frame\n",
    "    :param every: frame spacing\n",
    "    :return: count of images saved\n",
    "    \"\"\" \n",
    "    \n",
    "    video_path = os.path.normpath(video_path)\n",
    "    frame_dir = os.path.normpath(frame_dir)\n",
    "    \n",
    "    video_dir, video_filename = os.path.split(video_path)\n",
    "    video_filename = os.path.splitext(video_filename)[0]\n",
    "    assert os.path.exists(video_path)\n",
    "    \n",
    "    capture = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if start < 0:\n",
    "        start = 0\n",
    "    if end < 0:\n",
    "        end = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    capture.set(1, start)\n",
    "    frame = start\n",
    "    while_safety = 0\n",
    "    saved_count = 0 \n",
    "    \n",
    "    while frame < end:\n",
    "        _, image = capture.read()\n",
    "        \n",
    "        if while_safety > 10:  # break the while if our safety maxs out at 10\n",
    "            break\n",
    "            \n",
    "        if image is None:\n",
    "            while_safety += 1\n",
    "            continue\n",
    "            \n",
    "        if frame % every == 0:\n",
    "            while_safety = 0\n",
    "            \n",
    "            save_path = os.path.join(frame_dir, video_filename, \"image.{:04d}.jpg\".format(saved_count))\n",
    "            \n",
    "            if not os.path.exists(os.path.join(frame_dir, video_filename)):\n",
    "                os.makedirs(os.path.join(frame_dir, video_filename))\n",
    "            if not os.path.exists(save_path) or overwrite:\n",
    "                cv2.imwrite(save_path, image)\n",
    "            \n",
    "            saved_count += 1\n",
    "                \n",
    "        frame += 1\n",
    "        \n",
    "    capture.release()\n",
    "        \n",
    "    return saved_count;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_count = extract_frame(\"../../../datas/sample_video/cut_ffmpeg.mp4\",\n",
    "                            \"../../../datas/extract_video/\",\n",
    "                            every=30,\n",
    "                            overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create DSL Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Makefile  config_infer.txt\t deepstream_preprocess_test.cpp\r\n",
      "README\t  config_preprocess.txt  test\r\n"
     ]
    }
   ],
   "source": [
    "!ls /opt/nvidia/deepstream/deepstream/sources/apps/sample_apps/deepstream-preprocess-test/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import time\n",
    "from dsl import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_image_source_dir = \\\n",
    "    '../../../datas/extract_video/cut_ffmpeg/image.%04d.jpg'\n",
    "\n",
    "# Preprocessor config file is located under \"/deepstream-services-library/test/configs\"\n",
    "preproc_config_file = \\\n",
    "    '/opt/nvidia/deepstream/deepstream/sources/apps/sample_apps/deepstream-preprocess-test/config_preprocess.txt'\n",
    "    \n",
    "# Filespecs for the Primary GIE\n",
    "primary_infer_config_file = \\\n",
    "    '/opt/nvidia/deepstream/deepstream/sources/apps/sample_apps/deepstream-preprocess-test/config_infer.txt'\n",
    "\n",
    "# IMPORTANT! ensure that the model-engine was generated with the config from the Preprocessing example\n",
    "#  - apps/sample_apps/deepstream-preprocess-test/config_infer.txt\n",
    "primary_model_engine_file = \\\n",
    "    '/opt/nvidia/deepstream/deepstream/samples/models/Primary_Detector/resnet10.caffemodel_b3_gpu0_int8.engine'\n",
    "    \n",
    "tracker_config_file = \\\n",
    "    '/opt/nvidia/deepstream/deepstream/samples/configs/deepstream-app/config_tracker_IOU.yml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config_infer_primary_yoloV5s.txt   deepstream_app_config_yoloV5s.txt\r\n",
      "config_preprocess_v5s.txt\t   labels_coco.txt\r\n",
      "config_tracker_IOU.yml\t\t   libnvdsinfer_custom_impl_Yolo.so\r\n",
      "config_tracker_NvDCF_accuracy.yml  yolov5s.cfg\r\n",
      "config_tracker_NvDCF_max_perf.yml  yolov5s.wts\r\n"
     ]
    }
   ],
   "source": [
    "!ls /opt/dsl/datas/coco_s_640_cu114/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_image_source_dir = \\\n",
    "    '../../../datas/extract_video/cut_ffmpeg/image.%04d.jpg'\n",
    "\n",
    "# Preprocessor config file is located under \"/deepstream-services-library/test/configs\"\n",
    "preproc_config_file = \\\n",
    "    '/opt/dsl/datas/coco_s_640_cu114/config_preprocess_v5s.txt'\n",
    "    \n",
    "# Filespecs for the Primary GIE\n",
    "primary_infer_config_file = \\\n",
    "    '/opt/dsl/datas/coco_s_640_cu114/config_infer_primary_yoloV5s.txt'\n",
    "\n",
    "# IMPORTANT! ensure that the model-engine was generated with the config from the Preprocessing example\n",
    "#  - apps/sample_apps/deepstream-preprocess-test/config_infer.txt\n",
    "primary_model_engine_file = \\\n",
    "    '/opt/dsl/datas/coco_s_640_cu114/'\n",
    "    \n",
    "nmp_label_file = \\\n",
    "    '/opt/dsl/datas/coco_s_640_cu114/labels_coco.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PGIE_CLASS_ID_VEHICLE = 0\n",
    "PGIE_CLASS_ID_BICYCLE = 1\n",
    "PGIE_CLASS_ID_PERSON = 2\n",
    "PGIE_CLASS_ID_ROADSIGN = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "# Function to be called on XWindow KeyRelease event\n",
    "## \n",
    "def xwindow_key_event_handler(key_string, client_data):\n",
    "    print('key released = ', key_string)\n",
    "    if key_string.upper() == 'P':\n",
    "        dsl_pipeline_pause('pipeline')\n",
    "    elif key_string.upper() == 'R':\n",
    "        dsl_pipeline_play('pipeline')\n",
    "    elif key_string.upper() == 'Q' or key_string == '\u001b' or key_string == '\u0003':\n",
    "        dsl_pipeline_stop('pipeline')\n",
    "        dsl_main_loop_quit()\n",
    "\n",
    "##\n",
    "# Function to be called on XWindow Delete event\n",
    "## \n",
    "def xwindow_delete_event_handler(client_data):\n",
    "    print('delete window event')\n",
    "    dsl_pipeline_stop('pipeline')\n",
    "    dsl_main_loop_quit()\n",
    "\n",
    "    \n",
    "## \n",
    "# Function to be called on End-of-Stream (EOS) event\n",
    "## \n",
    "def eos_event_listener(client_data):\n",
    "    print('Pipeline EOS event')\n",
    "    \n",
    "## \n",
    "# Function to be called on every change of Pipeline state\n",
    "## \n",
    "def state_change_listener(old_state, new_state, client_data):\n",
    "    print('previous state = ', old_state, ', new state = ', new_state)\n",
    "    if new_state == DSL_STATE_PLAYING:\n",
    "        dsl_pipeline_dump_to_dot('pipeline', \"state-playing\")\n",
    "\n",
    "## \n",
    "# Function to be called on Object Capture (and file-save) complete\n",
    "## \n",
    "def capture_complete_listener(capture_info_ptr, client_data):\n",
    "    print(' ***  Object Capture Complete  *** ')\n",
    "    \n",
    "    capture_info = capture_info_ptr.contents\n",
    "    print('capture_id: ', capture_info.capture_id)\n",
    "    print('filename:   ', capture_info.filename)\n",
    "    print('dirpath:    ', capture_info.dirpath)\n",
    "    print('width:      ', capture_info.width)\n",
    "    print('height:     ', capture_info.height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "\n",
    "    # Since we're not using args, we can Let DSL initialize GST on first call\n",
    "    while True:\n",
    "\n",
    "        # --------------------------------------------------------------------------------\n",
    "        # Step 1: We build the (final stage) Inference Pipeline with an Image-Source,\n",
    "        # Preprocessor, Primary GIE, IOU Tracker, On-Screen Display, and Window Sink.\n",
    "         \n",
    "        retval = dsl_source_image_multi_new('multi-image-source', multi_image_source_dir, 30, 1)\n",
    "        if retval != DSL_RETURN_SUCCESS:\n",
    "            break\n",
    "        \n",
    "        # New Preprocessor component using the config filespec defined above.\n",
    "        retval = dsl_preproc_new('preprocessor', preproc_config_file)\n",
    "        if retval != DSL_RETURN_SUCCESS:\n",
    "            break\n",
    "            \n",
    "        # New Primary GIE using the filespecs above with interval = 0\n",
    "        retval = dsl_infer_gie_primary_new('primary-gie', \n",
    "            primary_infer_config_file, None, 0)\n",
    "        if retval != DSL_RETURN_SUCCESS:\n",
    "            break\n",
    "        \n",
    "        retval = dsl_infer_batch_size_set('primary-gie', 4)\n",
    "        if retval != DSL_RETURN_SUCCESS:\n",
    "            break\n",
    "            \n",
    "        # **** IMPORTANT! we must set the input-meta-tensor setting to true when\n",
    "        # using the preprocessor, otherwise the GIE will use its own preprocessor.\n",
    "        retval = dsl_infer_gie_tensor_meta_settings_set('primary-gie',\n",
    "            input_enabled=True, output_enabled=False);\n",
    "        if retval != DSL_RETURN_SUCCESS:\n",
    "            break\n",
    "              \n",
    "        retval = dsl_pph_nmp_new('nmp-pph', None,\n",
    "            1, 1, 0.5);\n",
    "        if retval != DSL_RETURN_SUCCESS:\n",
    "            break\n",
    "            \n",
    "        # New OSD with text and bbox display enabled. \n",
    "        retval = dsl_osd_new('on-screen-display', \n",
    "            text_enabled=True, clock_enabled=True, bbox_enabled=True, mask_enabled=False)\n",
    "        if retval != DSL_RETURN_SUCCESS:\n",
    "            break\n",
    "        \n",
    "        retval = dsl_osd_pph_add('on-screen-display', 'nmp-pph', DSL_PAD_SINK)\n",
    "        if retval != DSL_RETURN_SUCCESS:\n",
    "            break\n",
    "            \n",
    "        # New Window Sink, 0 x/y offsets and same dimensions as Tiled Display\n",
    "        retval = dsl_sink_window_new('window-sink', 0, 0, \n",
    "            width=DSL_STREAMMUX_DEFAULT_WIDTH, height=DSL_STREAMMUX_DEFAULT_HEIGHT)\n",
    "        if retval != DSL_RETURN_SUCCESS:\n",
    "            break\n",
    "\n",
    "        # Add all the components to our pipeline\n",
    "        retval = dsl_pipeline_new_component_add_many('pipeline', components=[\n",
    "            'multi-image-source', 'preprocessor', 'primary-gie',\n",
    "            'on-screen-display', 'window-sink', None])\n",
    "        if retval != DSL_RETURN_SUCCESS:\n",
    "            break\n",
    "        \n",
    "        # Add the XWindow event handler functions defined above\n",
    "        retval = dsl_pipeline_xwindow_key_event_handler_add(\"pipeline\", xwindow_key_event_handler, None)\n",
    "        if retval != DSL_RETURN_SUCCESS:\n",
    "            break\n",
    "        retval = dsl_pipeline_xwindow_delete_event_handler_add(\"pipeline\", xwindow_delete_event_handler, None)\n",
    "        if retval != DSL_RETURN_SUCCESS:\n",
    "            break\n",
    "\n",
    "        ## Add the listener callback functions defined above\n",
    "        retval = dsl_pipeline_state_change_listener_add(\"pipeline\", state_change_listener, None)\n",
    "        if retval != DSL_RETURN_SUCCESS:\n",
    "            break\n",
    "\n",
    "        # Play the pipeline\n",
    "        retval = dsl_pipeline_play('pipeline')\n",
    "        if retval != DSL_RETURN_SUCCESS:\n",
    "            break\n",
    "\n",
    "        dsl_main_loop_run()\n",
    "        retval = DSL_RETURN_SUCCESS\n",
    "        break\n",
    "\n",
    "    # Print out the final result\n",
    "    print(dsl_return_value_to_string(retval))\n",
    "\n",
    "    dsl_pipeline_delete_all()\n",
    "    dsl_component_delete_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit(main(sys.argv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
